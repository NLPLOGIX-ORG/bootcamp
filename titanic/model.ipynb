{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0dcf0d183da212cc343f73d010fd93a1ec6647daf2740ea9a29b8b3a76ed3cb37",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Titanic - Machine Learning from Disaster"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Importing Packages\n",
    "Python packages are software modules which can be installed into your class hierarchy. [Pandas](https://pandas.pydata.org/) and [Scikit-Learn](https://scikit-learn.org/stable/index.html) are popular for machine learning and data science.\n",
    "\n",
    "### Pandas\n",
    "Pandas is a well known python library that deals with modifying, analyzing, and creating dataframes. We will use this for all of our data manipulation needs as we get further into making our models. \n",
    "We use the 'as' keyword to modify the name of the module. You will see this used later when we call functions from the pandas class."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "### Scikit-Learn\n",
    "Sklearn is free software machine learning library which provides several models and functions to help us evalute, modify, and train our model. \n",
    "We use the 'from' keyword to limit the scope of the module. Instead of importing the entire scikit-learn library, we can choose to just import [RandomForestClassifer](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and the [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "source": [
    "### Python Standard Library - os\n",
    "This module provides a portable way of using operating system dependent functionality."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "source": [
    "## Loading the Data\n",
    "We will demonstrate how to load data and read data into python using pandas.\n",
    "\n",
    "### Path\n",
    "It is generally good practice to use relative paths when loading data. This is because the absolute path of a string will change across computers. For this example, we have placed the data files at the same level of this script, so its name exists in memory as a parameter in the function below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"train.csv\""
   ]
  },
  {
   "source": [
    "### DataFrame\n",
    "Using the path above, we can call the [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function from pandas. This will read in our data from \"train.csv\" and return a DataFrame with labeled axes. You can see the first five rows of the dataframe by calling the `head()` function."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train_data = pd.read_csv(data_dir)\n",
    "train_data.head()"
   ]
  },
  {
   "source": [
    "## Setting up the model\n",
    "We will now go into the basic procedure that goes into creating a model with pandas and sklearn.\n",
    "\n",
    "\n",
    "### Y-variable and features\n",
    "Before we can create our model, we must first setup our data to be ready to train and test on our model. We do this by first identifying our y-variable, which is the variable the model predicts on. In this data set, our y-variable is the \"Survived\" column.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data[\"Survived\"]"
   ]
  },
  {
   "source": [
    "Now that we have our y-variable, we must decide what features our model will use in order to predict. Features are just columns in a dataset which can take categorical or numeric values. For this model, simple we will choose four features (\"Pclass\", \"Sex\", \"SibSp\", \"Parch\") and store them in an array."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]"
   ]
  },
  {
   "source": [
    "### Data Conversion\n",
    "Now that we have loaded in our testing and training data, we will filter them into new dataframes using only the features we discussed earlier. It is on these dataframes that we will test and train our model. However, in our features we have a mix of categorical and numerical data points. This will not work well as our model needs only numerical data. To fix this, we will convert our categorical data to numeric through the pandas function `get.dummies()`.This function will take all unique categorical variables and create their own column within the dataset that's marked with either a 1 or 0. For more on [get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)\n",
    "\n",
    "`pd.get_dummies()`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Pclass  SibSp  Parch  Sex_female  Sex_male\n",
       "0       3      1      0           0         1\n",
       "1       1      1      0           1         0\n",
       "2       3      0      0           1         0\n",
       "3       1      1      0           1         0\n",
       "4       3      0      0           0         1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "X = pd.get_dummies(train_data[features])\n",
    "X.head()"
   ]
  },
  {
   "source": [
    "Notice the dataframe above updated the feature 'Sex' into two dummy columns with numeric values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Train and Test Split Data\n",
    "Now that we have a new data frame with our desired features, we will now randomly split our data into our training and testing dataset. We will do this by utilizing sklearn's `train_test_split` function. This is often how you will get data in order to test your model where you just take a portion of the original data to test on. With train_test_split, we can also specify how to split our data, so in this example we'll do it by allocating 70% of our data to training our model while 30% goes to testing our model. The random state parameter corresponds to the random seed we give `train_test_split`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=0)"
   ]
  },
  {
   "source": [
    "**Note** - train_x and train_y are now the dataframe and y-variable we will use to train our model while test_X and test_y are the equivalent for our testing data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## RandomForestClassifier Model\n",
    "Finally, we can start building our model. As mentioned before, we will be using a [Random Forest Classifier model](https://towardsdatascience.com/understanding-random-forest-58381e0602d2). This type a model uses what are known as decision trees in order to decide how it will predict. A decision tree uses the features we pass into it in order to make a prediction on our y-variable, in this case \"Survival\". Once all the decision trees have made their decision, the most voted prediction is chosen from the group of trees and that is the result returned."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)"
   ]
  },
  {
   "source": [
    "## Training and Testing \n",
    "We will now train the model with our training data and our y-variable. This easily done using sklearn `fit()` function."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "model.fit(train_X,train_y)"
   ]
  },
  {
   "source": [
    "Finally, we test the model vs. the testing data and save this as our predictions variable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(test_X)"
   ]
  },
  {
   "source": [
    "## Results\n",
    "Now that we have trained and tested our model, we can see the accuracy using the roc_auc_score. The roc_auc_score is a way for predicting the accuracy of our model by taking the area under its Receiver Operating Characteristic Curve (ROC Curve). The ROC Curve is taken by plotting the True Positive Rate vs the False Positive Rate of the model. For more on ROC Curve is calculated [here](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc). We check the roc_auc_score as so.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ROC AUC Score: 0.7925\n"
     ]
    }
   ],
   "source": [
    "result = roc_auc_score(test_y, predictions)\n",
    "print(\"ROC AUC Score: \" + str(result))"
   ]
  },
  {
   "source": [
    "### Write to CSV\n",
    "Like we've seen before, you cannot only read from a CSV but can also write to CSV."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Feature Importance\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}